{"version":3,"file":"index.js","mappings":";;;;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB,oDAAoD,GAAG;AACvD;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,mBAAmB,GAAG;AACtB;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,mBAAmB;;;;;;;;;;;AC7GnB;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA,sBAAsB,wBAAwB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA,UAAU;AACV;AACA;;AAEA;AACA;AACA,UAAU;AACV;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,iCAAiC,8BAA8B;AAC/D;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA,iBAAiB;AACjB,aAAa;AACb,SAAS;AACT,KAAK;AACL;;AAEA,mBAAmB;;;;;;;UCnGnB;UACA;;UAEA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;;UAEA;UACA;;UAEA;UACA;UACA;;;;;;ACtBA,QAAQ,8BAA8B,EAAE,mBAAO,CAAC,yBAAQ;AACxD,QAAQ,oBAAoB,EAAE,mBAAO,CAAC,wEAAmB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D;AAC3D,2CAA2C,QAAQ,qBAAqB;AACxE;AACA;AACA,oFAAoF;AACpF,SAAS;AACT,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,mBAAmB;AACjE;AACA;AACA;AACA,sEAAsE,mBAAmB;AACzF;AACA;AACA;AACA,6DAA6D,WAAW,IAAI,kBAAkB;AAC9F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,sDAAsD;AAC7F;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,gBAAgB,eAAe,kCAAkC;AACnH;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAiD,eAAe;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,sBAAsB,0BAA0B;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB;AACnB;AACA;AACA;AACA,mBAAmB;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA","sources":["webpack:///./node_modules/tf_node_tokenizer/tokenizer.js","webpack:///./util.js","webpack:///webpack/bootstrap","webpack:///./script.js"],"sourcesContent":["class Tokenizer {\n  /**\n   * Class Tokenizer\n   * @param filters a string where each element is a character that will be filtered from the texts. The default is all punctuation, plus tabs and line breaks, minus the ' character.\n   * @param num_words the maximum number of words to keep, based on word frequency. Only the most common num_words-1 words will be kept.\n   * @param oov_token if given, it will be added to word_index and used to replace out-of-vocabulary words during text_to_sequence calls\n   * @param lower boolean. Whether to convert the texts to lowercase.\n   * @return tokenizer object\n   */\n  constructor(config = {}) {\n    this.filters = config.filters || /[\\\\.,/#!$%^&*;:{}=\\-_`~()]/g;\n    this.num_words = parseInt(config.num_words) || null;\n    this.oov_token = config.oov_token || \"\";\n    this.lower = typeof config.lower === \"undefined\" ? true : config.lower;\n\n    // Primary indexing methods. Word to index and index to word.\n    this.word_index = {};\n    this.index_word = {};\n\n    // Keeping track of word counts\n    this.word_counts = {};\n  }\n\n  cleanText(text) {\n    if (this.lower) text = text.toLowerCase();\n    return text\n      .replace(this.filters, \"\")\n      .replace(/\\s{2,}/g, \" \")\n      .split(\" \");\n  }\n\n  /**\n   * Updates internal vocabulary based on a list of texts.\n   * @param texts\tcan be a list of strings, a generator of strings (for memory-efficiency), or a list of list of strings.\n   */\n\n  fitOnTexts(texts) {\n    texts.forEach((text) => {\n      text = this.cleanText(text);\n      text.forEach((word) => {\n        this.word_counts[word] = (this.word_counts[word] || 0) + 1;\n      });\n    });\n\n    // Create words vector according to frequency (high to low)\n    let vec = Object.entries(this.word_counts).sort((a, b) => b[1] - a[1]);\n    // if oov_token is provided, add it to word_index / index_word\n    if (this.oov_token) vec.unshift([this.oov_token, 0]);\n    // Assign to word_index / index_word\n    vec.every(([word, number], i) => {\n      this.word_index[word] = i + 1;\n      this.index_word[i + 1] = word;\n      return true;\n    });\n  }\n\n  /**\n   * Transforms each text in texts to a sequence of integers.\n   * Only top num_words-1 most frequent words will be taken into account. Only words known by the tokenizer will be taken into account.\n   * @param texts\tA list of texts (strings).\n   * @return A list of sequences.\n   */\n  textsToSequences(texts) {\n    // Only translate the top num_words(if provided) of words.\n    return texts.map((text) =>\n      this.cleanText(text).flatMap((word) =>\n        this.word_index[word] &&\n        (this.num_words === null || this.word_index[word] < this.num_words)\n          ? this.word_index[word]\n          : this.oov_token\n          ? 1\n          : []\n      )\n    );\n  }\n\n  /**\n   * Returns a JSON string containing the tokenizer configuration. To load a tokenizer from a JSON string, use tokenizerFromJson(json_string).\n   * @param replacer A function that transforms the results. (Passing to JSON.stringify())\n   * @param space â€” Adds indentation, white space, and line break characters to thereturn-value JSON text to make it easier to read. (Passing to JSON.stringify())\n   * @return A list of sequences.\n   */\n  toJson(replacer, space) {\n    return JSON.stringify(\n      {\n        word_index: this.word_index,\n        index_word: this.index_word,\n        word_counts: this.word_counts,\n      },\n      replacer,\n      space\n    );\n  }\n}\n\n/**\n * Create tokenizer from Json string\n * @param json_string JSON string encoding a tokenizer configuration.\n * @return A tokenizer object\n */\nfunction tokenizerFromJson(json_string) {\n  const tokenizer = new Tokenizer();\n  const js = JSON.parse(json_string);\n  tokenizer.word_index = js.word_index;\n  tokenizer.index_word = js.index_word;\n  tokenizer.word_counts = js.word_counts;\n  return tokenizer;\n}\n\nmodule.exports = { Tokenizer, tokenizerFromJson };\n","// JS port of Keras Tokenizer by Copilot <3\nfunction pad_sequences(sequences, maxlen=null, dtype='int32', padding='pre', truncating='pre', value=0.0) {\n    if (!Array.isArray(sequences)) {\n        throw new Error(\"`sequences` must be iterable.\");\n    }\n    let num_samples = sequences.length;\n\n    let lengths = [];\n    let sample_shape = [];\n    let flag = true;\n\n    for (let x of sequences) {\n        try {\n            lengths.push(x.length);\n            if (flag && x.length) {\n                sample_shape = [x.length];\n                flag = false;\n            }\n        } catch (e) {\n            throw new Error(\"`sequences` must be a list of iterables. Found non-iterable: \" + x);\n        }\n    }\n\n    if (maxlen === null) {\n        maxlen = Math.max(...lengths);\n    }\n\n    let x = Array(num_samples).fill().map(() => Array(maxlen).fill(value));\n\n    for (let idx = 0; idx < sequences.length; idx++) {\n        let s = sequences[idx];\n        if (!s.length) {\n            continue;\n        }\n        let trunc;\n        if (truncating === 'pre') {\n            trunc = s.slice(-maxlen);\n        } else if (truncating === 'post') {\n            trunc = s.slice(0, maxlen);\n        } else {\n            throw new Error('Truncating type \"' + truncating + '\" not understood');\n        }\n\n        if (padding === 'post') {\n            x[idx].splice(0, trunc.length, ...trunc);\n        } else if (padding === 'pre') {\n            x[idx].splice(-trunc.length, trunc.length, ...trunc);\n        } else {\n            throw new Error('Padding type \"' + padding + '\" not understood');\n        }\n    }\n    return x;\n}\n\nasync function plot_history(canvas, path) {\n    const response = await fetch(path + '/history.json');\n    const history = await response.json();\n\n    const metrics = Object.keys(history.history);\n\n    if (window.histplot) {\n        window.histplot.destroy();\n    }\n\n    window.histplot = new Chart(canvas, {\n        type: 'line',\n        data: {\n            labels: Array.from({ length: history.epoch.length }, (_, i) => i + 1),\n            datasets: metrics.map(metric => ({\n                label: metric, data: history.history[metric],\n            })),\n        },\n        options: {\n            responsive: true,\n            title: {\n                display: true,\n                text: 'Model Training History',\n            },\n            scales: {\n                x: {\n                    display: true,\n                    scaleLabel: {\n                        display: true,\n                        labelString: 'Epoch',\n                    },\n                },\n                y: {\n                    display: true,\n                    scaleLabel: {\n                        display: true,\n                        labelString: 'Value',\n                    },\n                    type: 'logarithmic',\n                },\n            },\n        },\n    });\n}\n\nmodule.exports = { pad_sequences, plot_history };\n","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId](module, module.exports, __webpack_require__);\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n","const { pad_sequences, plot_history } = require('./util');\r\nconst { tokenizerFromJson } = require('tf_node_tokenizer');\r\n// ... (other code)\r\n\r\nwindow.tfmodel = null;\r\n\r\nlet inputs = [];\r\nlet models = [];\r\n\r\nconst maxSequenceInput = document.getElementById('max-sequence');\r\n\r\nconst n = (window.innerWidth || document.documentElement.clientWidth) < 768 ? 8 : 16;\r\n\r\ndocument.addEventListener('DOMContentLoaded', async () => {\r\n    inputs = await (await fetch('data.json')).json();\r\n    populateSelect(document.getElementById('input-select'), inputs);\r\n    await loadText(0);\r\n\r\n    document.getElementById('input-select').addEventListener('change', (event) => {\r\n        loadText(event.target.value);\r\n    });\r\n\r\n    document.getElementById('model-select').addEventListener('change', (event) => {\r\n        loadModel(event.target.value);\r\n    });\r\n\r\n    document.getElementById('user-input').addEventListener(\"input\", resizeTextbox, false);\r\n    document.getElementById('predict-btn').addEventListener('click', handlePrediction);\r\n    document.getElementById('continue-btn').addEventListener('click', predictWord);\r\n    document.getElementById('auto-btn').addEventListener('click', predictWords);\r\n    document.getElementById('stop-btn').addEventListener('click', stop);\r\n    document.getElementById('reset-btn').addEventListener('click', reset);\r\n\r\n    document.getElementById(\"text-input-form\").addEventListener(\"keyup\", event => {\r\n        if(event.key !== \"Enter\") return;\r\n        event.preventDefault();\r\n        predictWord()\r\n    });\r\n});\r\n\r\nfunction populateSelect(select, items) {\r\n    select.innerHTML = '';\r\n    items.forEach((item, index) => {\r\n        const option = document.createElement('option');\r\n        option.value = index;\r\n        option.textContent = item.name;\r\n        select.appendChild(option);\r\n    });\r\n}\r\n\r\nasync function loadText(index) {\r\n    reset();\r\n    const selectedText = inputs[index];\r\n    if (selectedText.models && selectedText.models.length > 0) {\r\n        models = selectedText.models;\r\n        populateSelect(document.getElementById('model-select'), selectedText.models);\r\n        await loadModel(0);\r\n    }\r\n\r\n    document.getElementById('examples').innerHTML = `<ul>${(selectedText.examples || []).map((example, index) =>\r\n        `<li><a href=\"#\" class=\"example\">${example}</a></li>`).join('')}</ul>`;\r\n    document.querySelectorAll('.example').forEach(button => {\r\n        button.addEventListener('click', (event) => {\r\n            document.getElementById('user-input').value = event.target.textContent; predictWords();\r\n        });\r\n    });\r\n}\r\n\r\nasync function loadModel(index) {\r\n    reset();\r\n    document.body.style.cursor = 'wait';\r\n    const selectedModel = models[index];\r\n    maxSequenceInput.value = selectedModel.maxSequenceLength ?? maxSequenceInput.value;\r\n\r\n    const model = await tf.loadLayersModel(`${selectedModel.path}/model.json`);\r\n    console.log('Model loaded:', model);\r\n    window.tfmodel = model;\r\n\r\n    await (window.tokenizer = tokenizerFromJson(await (await fetch(`${selectedModel.path}/dict.json`)).text()));\r\n\r\n    document.getElementById('predictions-table').innerHTML = null;\r\n    const modelInfo = document.getElementById('model-info');\r\n    modelInfo.innerHTML = model.layers.map(layer => `<span>${layer.name}: ${layer.outputShape}</span>`).join('<br>');\r\n\r\n    const canvas = document.getElementById('history').getContext('2d');\r\n    await plot_history(canvas, selectedModel.path);\r\n\r\n    await model.predict(tf.zeros([1, parseInt(maxSequenceInput.value, 10)])).dataSync();\r\n    document.body.style.cursor = 'auto';\r\n}\r\n\r\nasync function handlePrediction(event) {\r\n    event.preventDefault();\r\n    const text = document.getElementById('user-input').value;\r\n    const numPreds = parseInt(document.getElementById('num-preds').value, 10);\r\n    const predictions = await generatePredictions(text, numPreds);\r\n    document.getElementById('continue-btn').disabled = false;\r\n    updatePredictionsTable(predictions);\r\n}\r\n\r\nasync function generatePredictions(text, numPredictions) {\r\n    const maxSeqLen = parseInt(maxSequenceInput.value, 10);\r\n    const sequence = pad_sequences([window.tokenizer.textsToSequences([text])[0]], maxSeqLen)[0];\r\n    const predictions = window.tfmodel.predict(tf.tensor([sequence])).dataSync();\r\n    calculatePerplexity(predictions)\r\n\r\n    return Array.from(predictions)\r\n        .map((probability, index) => ({word: window.tokenizer.index_word[index], probability}))\r\n        .sort((a, b) => b.probability - a.probability)\r\n        .slice(0, numPredictions);\r\n}\r\n\r\nfunction updatePredictionsTable(predictions) {\r\n    document.getElementById('predictions-table').innerHTML = predictions.map(prediction =>\r\n        `<tr><td><a href=\"#\" class=\"prediction\">${prediction.word}</a></td><td>${prediction.probability.toFixed(n)}</td></tr>`\r\n    ).join('');\r\n    document.querySelectorAll('.prediction').forEach(button => {\r\n        button.addEventListener('click', () => selectWord(button.textContent));\r\n    });\r\n}\r\n\r\nfunction resizeTextbox() {\r\n    document.getElementById('user-input').style.height = 'auto';\r\n    document.getElementById('user-input').style.height = (this.scrollHeight) + \"px\";\r\n}\r\n\r\nasync function selectWord(word) {\r\n    const userInput = document.getElementById('user-input');\r\n    userInput.value = userInput.value ? userInput.value + ' ' + word : word;\r\n    userInput.dispatchEvent(new Event('input', { bubbles: true }));\r\n    await handlePrediction(new Event('click'));\r\n}\r\n\r\nasync function predictWord() {\r\n    const text = document.getElementById('user-input').value;\r\n    const predictions = await generatePredictions(text, 1);\r\n    if (predictions.length > 0) await selectWord(predictions[0].word)\r\n    await new Promise(resolve => setTimeout(resolve, 1));\r\n}\r\n\r\nlet auto = false;\r\nasync function predictWords() {\r\n    auto = true;\r\n    document.getElementById('auto-btn').style.display = 'none';\r\n    document.getElementById('stop-btn').style.display = 'inline-block';\r\n    const numWords = parseInt(document.getElementById('num-words').value, 10);\r\n    for (let i = 0; i < numWords && auto; i++) await predictWord(); auto = false;\r\n    document.getElementById('auto-btn').style.display = 'inline-block';\r\n    document.getElementById('stop-btn').style.display = 'none';\r\n}\r\n\r\nfunction stop() {\r\n    auto = false;\r\n}\r\n\r\nfunction reset() {\r\n    document.getElementById('predictions-table').innerHTML = '';\r\n    document.getElementById('continue-btn').disabled = true;\r\n    document.getElementById('user-input').value = '';\r\n    document.getElementById('num-words').value = 10\r\n    document.getElementById('num-preds').value = 5;\r\n    document.getElementById('perplexity').innerText = parseInt(0).toFixed(n);\r\n    perplexity = { log: 0, words: 0, result: 0 };\r\n    resizeTextbox()\r\n}\r\n\r\nlet perplexity = { log: 0, words: 0, result: 0 };\r\nfunction calculatePerplexity(predictions) {\r\n    perplexity.log += Math.log(predictions[tf.argMax(predictions).dataSync()[0]]);\r\n    perplexity.words++;\r\n    perplexity.result = Math.exp(-perplexity.log / perplexity.words);\r\n    document.getElementById('perplexity').innerText = perplexity.result.toFixed(n);\r\n}\r\n\r\n// const tf = require('@tensorflow/tfjs');\r\n"],"names":[],"sourceRoot":""}